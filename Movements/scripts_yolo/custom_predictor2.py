# custom_predictor.py
# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license
import torch
import torch.nn as nn

from ultralytics.models.yolo.detect import DetectionPredictor
from ultralytics.utils import ops


class CustomAEPredictor(DetectionPredictor):
    # 8.3.x: __init__(overrides, _callbacks) ì‹œê·¸ë‹ˆì²˜
    def __init__(self, overrides=None, _callbacks=None):
        super().__init__(overrides=overrides, _callbacks=_callbacks)
        # ì•ˆì „ ëª¨ë“œ
        if hasattr(self, "args") and self.args is not None:
            self.args.half = False
            self.args.amp = False
            # â— YAML ê²½ë¡œê°€ ë‚¨ì•„ìˆìœ¼ë©´ AutoBackendê°€ íŒŒì¼ë¡œ ë¡œë”© ì‹œë„ â†’ ë¹„ì›Œë‘”ë‹¤
            try:
                if getattr(self.args, "model", None):
                    self.args.model = None
            except Exception:
                pass
        self.autoencoder = None  # setup_modelì—ì„œ ì—°ê²°

    def _unwrap_core(self, m):
        """YOLO ë˜í¼(model) â†’ ë‚´ë¶€ DetectionModel(nn.Module)ë¡œ í’€ê¸°."""
        if m is None:
            return None
        core = getattr(m, "model", None)
        return core if isinstance(core, nn.Module) else (m if isinstance(m, nn.Module) else None)

    def setup_model(self, model=None):
        """
        Predictorê°€ ë°›ëŠ” model ì¸ìë¥¼ ìš°ì„  ì‚¬ìš©í•˜ê³ (Noneì´ë©´ self.model ì‚¬ìš©),
        YOLO ë˜í¼ë¼ë©´ ë‚´ë¶€ nn.Module(DetectionModel)ë¡œ í’€ì–´ì„œ AutoBackendì— ë„˜ê¸´ë‹¤.
        ë˜í•œ args.model(YAML ê²½ë¡œ)ì„ ë¹„ì›Œ íŒŒì¼ ë¡œë”©ì„ ì°¨ë‹¨í•œë‹¤.
        """
        # 1) model í•´ì„ (None â†’ self.model, ë˜í¼ â†’ core nn.Module)
        m = model if model is not None else getattr(self, "model", None)
        core = self._unwrap_core(m)

        # 2) YAML ë¡œë”© ì°¨ë‹¨
        if hasattr(self, "args") and self.args is not None:
            try:
                if getattr(self.args, "model", None):
                    self.args.model = None
            except Exception:
                pass

        # 3) ìƒìœ„ì— nn.Moduleì„ ë„˜ê¸°ë©´ AutoBackendê°€ in-memory ëª¨ë¸ë¡œ ì…‹ì—…
        super().setup_model(core if core is not None else m)

        # 4) warmup ì—†ëŠ” ë²„ì „ ëŒ€ë¹„
        m2 = getattr(self, "model", None)
        if m2 is not None and not hasattr(m2, "warmup"):
            setattr(m2, "warmup", lambda *a, **k: None)

        # 5) AE ì—°ê²° ë° FP32 ê°•ì œ
        #   - self.modelê°€ ë˜í¼ë©´ ë˜í¼â†’core ìˆœìœ¼ë¡œ autoencoder ê²€ìƒ‰
        ae = None
        if m is not None and getattr(m, "autoencoder", None) is not None:
            ae = m.autoencoder
        if ae is None and core is not None and getattr(core, "autoencoder", None) is not None:
            ae = core.autoencoder

        if ae is not None:
            self.autoencoder = ae
            self.autoencoder.float()
        # Predictor ë‚´ë¶€ ëª¨ë¸ë„ FP32
        if hasattr(self, "model") and self.model is not None:
            try:
                self.model.float()
            except Exception:
                pass

        # 6) âœ… Predictorê°€ ê¸°ëŒ€í•˜ëŠ” ì†ì„± ê°•ì œ ì£¼ì…
        #    - AutoBackend/DetectionModel ì–´ëŠ ìª½ì´ë”ë¼ë„ fp16 ì†ì„± ë³´ì¥
        if hasattr(self, "model") and not hasattr(self.model, "fp16"):
            try:
                setattr(self.model, "fp16", False)
            except Exception:
                pass
        #    - self.device ë³´ì¥
        if not hasattr(self, "device") or self.device is None:
            try:
                self.device = next(self.model.parameters()).device
            except Exception:
                self.device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

    def preprocess(self, im):
        # â›‘ï¸ UL preprocessê°€ self.model.fp16ì— ì ‘ê·¼í•˜ë¯€ë¡œ ì—¬ê¸°ì„œë„ 1íšŒ ë” ë³´ì¥
        try:
            if not hasattr(self.model, "fp16"):
                setattr(self.model, "fp16", False)
        except Exception:
            pass
        if not hasattr(self, "device") or self.device is None:
            try:
                self.device = next(self.model.parameters()).device
            except Exception:
                self.device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

        im = super().preprocess(im)             # [B,C,H,W], [0,1]
        im = im.to(self.device).float().clamp(0.0, 1.0)
        ae = getattr(self.model, "autoencoder", None) or self.autoencoder
        if ae is not None:
            with torch.no_grad():
                out = ae(im)
                out = out[0] if isinstance(out, tuple) else out
                out = out.float().clamp(0.0, 1.0)
                if out.ndim != 4:
                    raise RuntimeError(f"[CustomAEPredictor] AE output must be 4D, got {out.shape}")
                if out.shape[1] == 3:
                    return out
                i_1ch = im[:, 0:1] if im.shape[1] > 1 else im
                diff = (i_1ch - out).abs()
                return torch.cat([i_1ch, out, diff], dim=1)
        return im

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # NAS ìŠ¤íƒ€ì¼ ì›ì‹œ ì¶œë ¥ í›„ì²˜ë¦¬ ì§€ì› (xyxyâ†’xywh + concat(scores)) â†’ ìƒìœ„ postprocess
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def postprocess(self, preds_in, img, orig_imgs):
        """
        NAS ê³„ì—´ ì¶œë ¥ì²˜ëŸ¼ [bboxes_xyxy, class_scores] ë˜ëŠ” [[bboxes_xyxy, class_scores]] í˜•íƒœë¥¼ ìë™ ì¸ì‹í•˜ì—¬
        xywhë¡œ ë³€í™˜ í›„ ìƒìœ„ postprocessì— ë§ëŠ” í…ì„œë¡œ ë³€í™˜í•œë‹¤.
        - bboxes: [B, N, 4] (xyxy)
        - scores: [B, N, C]
        ë³€í™˜ í›„:
        - preds:  [B, 4+C, N]  (UL postprocess ê¸°ëŒ€ í˜•ì‹)
        ë‹¤ë¥¸ í¬ë§·ì´ë©´ ì•ˆì „í•˜ê²Œ super().postprocessë¡œ í´ë°±í•œë‹¤.
        """
        try:
            bboxes, scores = None, None

            # Case A) preds_in = [bboxes, scores]
            if isinstance(preds_in, (list, tuple)) and len(preds_in) >= 2 and \
               torch.is_tensor(preds_in[0]) and torch.is_tensor(preds_in[1]):
                bboxes, scores = preds_in[0], preds_in[1]

            # Case B) preds_in = [[bboxes, scores]] (ë°°ì¹˜ ë˜í•‘)
            elif isinstance(preds_in, (list, tuple)) and len(preds_in) == 1:
                inner = preds_in[0]
                if isinstance(inner, (list, tuple)) and len(inner) >= 2 and \
                   torch.is_tensor(inner[0]) and torch.is_tensor(inner[1]):
                    bboxes, scores = inner[0], inner[1]

            # bboxes/scoresê°€ ë°œê²¬ë˜ë©´ NAS ìŠ¤íƒ€ì¼ë¡œ ë³€í™˜
            if bboxes is not None and scores is not None:
                # ë°°ì¹˜ ì°¨ì› ë³´ì •: [N,4] / [N,C] â†’ [1,N,4] / [1,N,C]
                if bboxes.ndim == 2:
                    bboxes = bboxes.unsqueeze(0)
                if scores.ndim == 2:
                    scores = scores.unsqueeze(0)

                # xyxy â†’ xywh
                boxes_xywh = ops.xyxy2xywh(bboxes)

                # [B,N,4] + [B,N,C] â†’ [B,N,4+C] â†’ [B,4+C,N]
                preds = torch.cat((boxes_xywh, scores), dim=-1).permute(0, 2, 1).contiguous()

                return super().postprocess(preds, img, orig_imgs)

        except Exception as e:
            print(f"[CustomAEPredictor] postprocess(NAS-like) fallback due to: {e}")

        # ì¸ì‹ ë¶ˆê°€ í¬ë§·ì´ë©´ ì›í˜• ê²½ë¡œë¡œ ì²˜ë¦¬
        return super().postprocess(preds_in, img, orig_imgs)
