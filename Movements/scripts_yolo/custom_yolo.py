from pathlib import Path
from typing import Any, Dict, List, Optional, Union

from custom_trainer import CustomAETrainer
from custom_validator import CustomAEValidator
# from custom_predictor import CustomAEPredictor
from custom_predictor2 import CustomAEPredictor  # â† í˜„ì¬ í”„ë¡œì íŠ¸ì—ì„œ ì‚¬ìš©í•˜ëŠ” Predictor

import ultralytics.nn.tasks
import torch
import torch.nn as nn
import torch.nn.functional as F
from ultralytics.nn.modules.ae import AutoEncoder
from ultralytics.nn.modules.losses_ae import hybrid_loss
from ultralytics.data.build import load_inference_source
from ultralytics.engine.model import Model
from ultralytics.models import yolo
from ultralytics.nn.tasks import (
    ClassificationModel,
    DetectionModel,
    OBBModel,
    PoseModel,
    SegmentationModel,
    WorldModel,
    YOLOEModel,
    YOLOESegModel,
)

from ultralytics.utils import ROOT, YAML
from ultralytics.nn.modules.attention import CBAM, SEBlock, ChannelAttention, SpatialAttention
import ultralytics.nn.tasks as tasks

# YAML íŒŒì„œê°€ ì°¸ì¡°í•˜ëŠ” tasks.py ì „ì—­ì— ë“±ë¡
tasks.CBAM = CBAM
tasks.SEBlock = SEBlock
tasks.ChannelAttention = ChannelAttention
tasks.SpatialAttention = SpatialAttention

ROOT_DIR = Path(__file__).resolve().parent.parent


def _ensure_device_consistency(self_model: nn.Module):
    """
    ëª¨ë¸ê³¼ ëª¨ë¸ì— ë¶€ì°©ëœ AEì˜ device/dtypeì„ ì¼ê´€í™”í•œë‹¤.
    - ê¸°ì¤€ì€ self_model(DetectionModel)ì˜ ì²« ë²ˆì§¸ íŒŒë¼ë¯¸í„°.
    - AEê°€ ì¡´ì¬í•˜ë©´ ë™ì¼ device/dtypeìœ¼ë¡œ ì´ë™í•˜ê³ , eval ìƒíƒœë¥¼ ì •ë ¬.
    """
    tgt: nn.Module = getattr(self_model, "module", self_model)
    # ê¸°ì¤€ íŒŒë¼ë¯¸í„°
    try:
        p = next(tgt.parameters())
        dev, dt = p.device, p.dtype
    except StopIteration:
        dev, dt = (torch.device("cuda" if torch.cuda.is_available() else "cpu"), torch.float32)

    # AE ì •ë ¬
    ae = getattr(tgt, "autoencoder", None)
    if ae is not None:
        try:
            ae.to(device=dev, dtype=dt)
        except Exception:
            # ì¼ë¶€ PyTorch ë²„ì „ì—ì„œ dtype ì¸ìë¥¼ ë¬´ì‹œí•˜ëŠ” ê²½ìš°ê°€ ìˆì–´ 2ë‹¨ê³„ë¡œ ë³´ì •
            ae.to(dev)
            try:
                for mp in ae.parameters():
                    mp.data = mp.data.to(dt)
            except Exception:
                pass
        if not tgt.training:
            ae.eval()


class YOLO(Model):
    def __init__(self, model: Union[str, Path], task=None, verbose=False, fold=None):
        path = Path(model if isinstance(model, (str, Path)) else "")
        print(f"[DEBUG] ëª¨ë¸ ë¡œë”©: path={path}, stem={path.stem}, suffix={path.suffix}")

        if "-world" in path.stem and path.suffix in {".pt", ".yaml", ".yml"}:
            new_instance = YOLOWorld(path, verbose=verbose)
            self.__class__ = type(new_instance)
            self.__dict__ = new_instance.__dict__

        elif "ae" in path.stem and path.suffix in {".pt", ".yaml", ".yml"}:
            print("[DEBUG] YOLOEAutoEncoder ë¡œë”©")
            new_instance = YOLOEAutoEncoder(path, task=task, verbose=verbose, fold=fold)
            self.__class__ = type(new_instance)
            self.__dict__ = new_instance.__dict__
        else:
            super().__init__(model=model, task=task, verbose=verbose)
            from ultralytics.models.yolo.yoloe.head import YOLOEDetect
            print("[DEBUG] ëª¨ë¸ ë§ˆì§€ë§‰ ë ˆì´ì–´:", type(self.model.model[-1]))
            print("[DEBUG] YOLOEDetect ì¸ì§€ ì—¬ë¶€:", isinstance(self.model.model[-1], YOLOEDetect))

            if hasattr(self.model, "model") and "RTDETR" in self.model.model[-1]._get_name():
                from ultralytics import RTDETR
                new_instance = RTDETR(self)
                self.__class__ = type(new_instance)
                self.__dict__ = new_instance.__dict__

    @property
    def task_map(self) -> Dict[str, Dict[str, Any]]:
        return {
            "classify": {
                "model": ClassificationModel,
                "trainer": yolo.classify.ClassificationTrainer,
                "validator": yolo.classify.ClassificationValidator,
                "predictor": yolo.classify.ClassificationPredictor,
            },
            "detect": {
                "model": DetectionModel,
                "trainer": yolo.detect.DetectionTrainer,
                "validator": yolo.detect.DetectionValidator,
                "predictor": yolo.detect.DetectionPredictor,
            },
            "segment": {
                "model": SegmentationModel,
                "trainer": yolo.segment.SegmentationTrainer,
                "validator": yolo.segment.SegmentationValidator,
                "predictor": yolo.segment.SegmentationPredictor,
            },
            "pose": {
                "model": PoseModel,
                "trainer": yolo.pose.PoseTrainer,
                "validator": yolo.pose.PoseValidator,
                "predictor": yolo.pose.PosePredictor,
            },
            "obb": {
                "model": OBBModel,
                "trainer": yolo.obb.OBBTrainer,
                "validator": yolo.obb.OBBValidator,
                "predictor": yolo.obb.OBBPredictor,
            },
        }


class YOLOWorld(Model):
    def __init__(self, model: Union[str, Path] = "yolov8s-world.pt", verbose: bool = False) -> None:
        super().__init__(model=model, task="detect", verbose=verbose)
        if not hasattr(self.model, "names"):
            self.model.names = YAML.load(ROOT / "cfg/datasets/coco8.yaml").get("names")

    @property
    def task_map(self) -> Dict[str, Dict[str, Any]]:
        return {
            "detect": {
                "model": WorldModel,
                "trainer": yolo.world.WorldTrainer,
                "validator": yolo.detect.DetectionValidator,
                "predictor": yolo.detect.DetectionPredictor,
            }
        }

    def set_classes(self, classes: List[str]) -> None:
        self.model.set_classes(classes)
        if " " in classes:
            classes.remove(" ")
        self.model.names = classes
        if self.predictor:
            self.predictor.model.names = classes


class YOLOEAutoEncoder(Model):
    def __init__(
        self,
        model: Union[str, Path] = "yoloe.yaml",
        task: Optional[str] = None,
        verbose: bool = False,
        fold: Optional[int] = None,
        ae_loss_fn=None,
    ):
        print("[DEBUG] YOLOEAutoEncoder ëª¨ë¸ ì´ˆê¸°í™”")
        super().__init__(model=model, task=task, verbose=verbose)

        # --- 1) AE ìƒì„± ë° (ì„ íƒ) ê°€ì¤‘ì¹˜ ë¡œë“œ -------------------------
        ae = AutoEncoder(loss_type="hybrid")
        self.ae_loss_type = "hybrid"
        self.ae_weights: Optional[Path] = None

        if fold is not None:
            ae_path = ROOT_DIR / "AE" / "pretrained_folds6" / f"pretrained_ae_fold{fold:02d}.pth"
            self.ae_weights = ae_path
            if ae_path.exists():
                print(f"ğŸ§  AE weights loaded from: {ae_path}")
                ae.load_state_dict(torch.load(ae_path, map_location="cpu"), strict=False)
            else:
                print(f"[WARN] AE weights not found at {ae_path}")

        # --- 2) DDP/DP ì•ˆì „ ë¶€ì°©: model.module ìš°ì„  --------------------
        tgt: nn.Module = getattr(self.model, "module", self.model)
        tgt.autoencoder = ae
        self.autoencoder = ae  # (ì„ íƒ) ë˜í¼ì—ë„ ë³´ê´€

        # --- 3) ëª¨ë¸ íŒŒë¼ë¯¸í„° ê¸°ì¤€ìœ¼ë¡œ ì¥ì¹˜/ì •ë°€ë„ ì •ë ¬ ----------------
        _ensure_device_consistency(self.model)

        # --- 4) ê¸°íƒ€ ì„¤ì • ----------------------------------------------
        self.ae_loss_fn = ae_loss_fn or hybrid_loss

        if not hasattr(self.model, "names"):
            self.model.names = YAML.load((ROOT / "cfg/datasets/coco8.yaml"))["names"]

    @property
    def task_map(self):
        return {
            "detect": {
                "model": YOLOEModel,
                "trainer": CustomAETrainer,
                "validator": CustomAEValidator,
                "predictor": CustomAEPredictor,  # â† ì»¤ìŠ¤í…€ Predictor ì‚¬ìš© (custom_predictor2)
            },
            "segment": {
                "model": YOLOESegModel,
                "trainer": yolo.yoloe.YOLOESegTrainer,
                "validator": yolo.yoloe.YOLOESegValidator,
                "predictor": yolo.segment.SegmentationPredictor,
            },
        }

    # (ì„ íƒ) ëª¨ë¸ ë‚´ë¶€ forwardì—ì„œ AEë¥¼ í†µê³¼ì‹œì¼œ ì‚¬ìš©í•˜ë ¤ëŠ” ê²½ìš° ìœ ì§€
    def forward(self, x, *args, **kwargs):
        print(f"[DEBUG AEâ†’YOLOE] forward í˜¸ì¶œ: x.shape={tuple(x.shape)}")
        tgt = getattr(self.model, "module", self.model)
        ae = getattr(tgt, "autoencoder", None)
        if ae is not None:
            # AE íŒŒë¼ë¯¸í„° ê¸°ì¤€ dtype/deviceë¡œ ì…ë ¥ ì •ë ¬
            try:
                p = next(ae.parameters())
                x = x.to(device=p.device, dtype=p.dtype, non_blocking=True)
            except StopIteration:
                pass

            # AE êµ¬ê°„ì€ fp32 ìœ ì§€(autocast ë¹„í™œì„±) â†’ dtype ì¶©ëŒ ì˜ˆë°©
            from torch.cuda.amp import autocast
            with autocast(enabled=False):
                x_ae = ae(x)
                x_ae = x_ae[0] if isinstance(x_ae, tuple) else x_ae

            if getattr(getattr(self, "overrides", {}), "verbose", False):
                print(f"[DEBUG AEâ†’YOLOE] AE ì¶œë ¥: x_ae.shape={tuple(x_ae.shape)}, mean={x_ae.mean().item():.4f}")
            return self.model(x_ae, *args, **kwargs)
        return self.model(x, *args, **kwargs)

    def compute_ae_loss(self, x):
        tgt = getattr(self.model, "module", self.model)
        ae = getattr(tgt, "autoencoder", None)
        if ae is None:
            raise RuntimeError("[YOLOEAutoEncoder.compute_ae_loss] AutoEncoder not attached to model.")

        # AE íŒŒë¼ë¯¸í„° ê¸°ì¤€ dtype/deviceë¡œ ì…ë ¥ ì •ë ¬
        try:
            p = next(ae.parameters())
            x = x.to(device=p.device, dtype=p.dtype, non_blocking=True)
        except StopIteration:
            pass

        with torch.no_grad():
            x_hat = ae.get_reconstruction(x)
        return hybrid_loss(x_hat, x)

    def val(self, validator=None, **kwargs):
        # â”€â”€ 0) eval ëª¨ë“œ ê³ ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        self.model.eval()
        tgt: nn.Module = getattr(self.model, "module", self.model)
        ae = getattr(tgt, "autoencoder", None)
        if ae is not None:
            ae.eval()
            print("[DEBUG] AutoEncoder loaded and set to eval()")
        else:
            print("[INFO] AE not found on wrapper; validator will re-attach if needed.")

        # â”€â”€ 1) args êµ¬ì„± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        data_path = kwargs.pop("data", None) or str(
            ROOT_DIR / "data" / "UMay" / "yolo_gas" / "yolo_split_fold01" / "data_aug_1var_5_gs.yaml"
        )
        args = {
            **getattr(self, "overrides", {}),
            **kwargs,
            "mode": "val",
            "data": data_path,
        }
        args["plots"] = False  # SciPy ì´ìŠˆ ë°©ì§€

        print(f"[DEBUG] validator args keys: {list(args.keys())}")
        print(f"[DEBUG] validator args['data']: {args['data']}")

        # â”€â”€ 2) validator í´ë˜ìŠ¤ ì„ íƒ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        validator_cls = validator or self._smart_load("validator")
        print(f"[DEBUG] validator class: {validator_cls}")

        # â”€â”€ 3) trainer í•„ìš” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        trainer = getattr(self, "trainer", None)
        if trainer is None:
            raise RuntimeError("[YOLO.val] Trainer is None. Call after training or attach a trainer before validation.")

        # ê¸°ì¡´ validator ì¬ì‚¬ìš©(ì—†ìœ¼ë©´ ìƒì„±)
        v = getattr(trainer, "validator", None)
        if v is None or not isinstance(v, validator_cls):
            v = validator_cls(
                model=self.model,        # EMA ì„ íƒì€ CustomAEValidatorê°€ ë‚´ë¶€ ì²˜ë¦¬
                dataloader=None,         # ì•„ë˜ì—ì„œ ìƒì„±
                save_dir=getattr(trainer, "save_dir", None),
                args=args,
                _callbacks=self.callbacks,
            )
            trainer.validator = v

        # â”€â”€ 4) dataloader ì—†ìœ¼ë©´ ìƒì„± (rank=-1ë¡œ ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤ ê²€ì¦) â”€â”€â”€
        if getattr(v, "dataloader", None) is None:
            split = args.get("split", "val")
            val_split = trainer.data.get(split) or trainer.data.get("val") or trainer.data.get("test")
            v.dataloader = trainer.get_dataloader(val_split, batch_size=trainer.batch_size, rank=-1, mode="val")

        # â”€â”€ 5) ê²€ì¦ ì‹¤í–‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        metrics = v(trainer)  # CustomAEValidator.__call__ì— FP32/AE ì¬ë¶€ì°©/EMA ì„ íƒ í¬í•¨

        # â”€â”€ 6) ê²°ê³¼ ì €ì¥ í›„ ë°˜í™˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        self.metrics = metrics
        return metrics

    def load(self, weights):
        print(f"[DEBUG] Loading YOLO weights from: {weights}")
        ckpt = torch.load(weights, map_location="cpu")

        model_dict = ckpt["model"] if "model" in ckpt else ckpt
        self.model.load_state_dict(model_dict, strict=False)
        print("[DEBUG] YOLO backbone weights loaded.")

        # --- AE ë‹¤ì‹œ ìƒì„± ë° ë¡œë“œ (DDP ì•ˆì „ ë¶€ì°©) ----------------------
        print("[DEBUG] Reattaching AutoEncoder...")
        ae = AutoEncoder(loss_type=self.ae_loss_type)

        if self.ae_weights is not None and Path(self.ae_weights).exists():
            ae.load_state_dict(torch.load(self.ae_weights, map_location="cpu"), strict=False)
            print(f"[DEBUG] AE weights loaded from: {self.ae_weights}")
        else:
            print("[WARN] AE weights not found or path is None.")

        tgt: nn.Module = getattr(self.model, "module", self.model)
        tgt.autoencoder = ae
        self.autoencoder = ae  # ë˜í¼ì—ë„ ë‹¤ì‹œ ë…¸ì¶œ

        # ëª¨ë¸ íŒŒë¼ë¯¸í„° ê¸°ì¤€ ì¥ì¹˜/ì •ë°€ë„ ì •ë ¬ + eval
        _ensure_device_consistency(self.model)
        return self
